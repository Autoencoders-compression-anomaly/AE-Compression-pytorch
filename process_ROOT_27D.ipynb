{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: AntiKt4EMTopoJetsAux.pt\n",
      "Reading: AntiKt4EMTopoJetsAux.eta\n",
      "Reading: AntiKt4EMTopoJetsAux.phi\n",
      "Reading: AntiKt4EMTopoJetsAux.m\n",
      "Reading: AntiKt4EMTopoJetsAuxDyn.ActiveArea4vec_eta\n",
      "Reading: AntiKt4EMTopoJetsAuxDyn.ActiveArea4vec_m\n",
      "Reading: AntiKt4EMTopoJetsAuxDyn.ActiveArea4vec_phi\n",
      "Reading: AntiKt4EMTopoJetsAuxDyn.ActiveArea4vec_pt\n",
      "Reading: AntiKt4EMTopoJetsAuxDyn.Jvt\n",
      "Reading: AntiKt4EMTopoJetsAuxDyn.JVFCorr\n",
      "Reading: AntiKt4EMTopoJetsAuxDyn.JvtRpt\n",
      "Reading: AntiKt4EMTopoJetsAuxDyn.FracSamplingMax\n",
      "Reading: AntiKt4EMTopoJetsAuxDyn.FracSamplingMaxIndex\n",
      "Reading: AntiKt4EMTopoJetsAuxDyn.Width\n",
      "Reading: AntiKt4EMTopoJetsAuxDyn.EMFrac\n",
      "Reading: AntiKt4EMTopoJetsAuxDyn.Timing\n",
      "Creating DataFrame...\n",
      "Head of data:\n",
      "        pt       eta       phi       m  ActiveArea4vec_eta  ActiveArea4vec_m  \\\n",
      "0  18432.0  0.796875  0.550781  4704.0            0.734375          0.160156   \n",
      "1  17152.0  0.980469 -0.384766  4128.0            1.000000          0.185547   \n",
      "2  17152.0  1.937500  2.250000  3440.0            1.960938          0.143555   \n",
      "3  15744.0 -1.835938 -0.225586  2592.0           -1.859375          0.151367   \n",
      "4  15680.0 -1.375000  2.671875  3376.0           -1.359375          0.143555   \n",
      "\n",
      "   ActiveArea4vec_phi  ActiveArea4vec_pt       Jvt   JVFCorr    JvtRpt  \\\n",
      "0            0.498047           0.527344  0.009277  0.259766  0.050781   \n",
      "1           -0.359375           0.585938  0.000000  0.000000  0.000000   \n",
      "2            2.265625           0.486328  0.010742  0.213867  0.029175   \n",
      "3           -0.221680           0.515625  0.656250  0.687500  0.207031   \n",
      "4            2.687500           0.498047  0.847656  0.812500  0.169922   \n",
      "\n",
      "   FracSamplingMax  FracSamplingMaxIndex     Width    EMFrac     Timing  \n",
      "0         0.351562                     0  0.237305  0.644531  -5.093750  \n",
      "1         0.406250                     2  0.221680  0.582031  11.250000  \n",
      "2         0.539062                     6  0.171875  0.820312  -1.343750  \n",
      "3         0.355469                     9  0.153320  0.558594  10.187500  \n",
      "4         0.337891                     2  0.195312  0.558594  -2.515625  \n",
      "Train data shape: (1220960, 16)\n",
      "Test data shape: (305240, 16)\n",
      "Saving processed_data/aod/compressed_all_jets_train.pkl\n",
      "Saving processed_data/aod/compressed_all_jets_test.pkl\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script unpacks the 27-dimensional data from the ROOT file to a pickled pandas dataframe\n",
    "\n",
    "See process_ROOT_4D for the 4-dimensional equivalent. \n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import uproot\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ROOTFilePath = 'data/user.elmsheus.20338515.EXT1._000004.DAOD_PHYS.data.pool.root'\n",
    "\n",
    "processed_folder = 'processed_data/aod/'\n",
    "\n",
    "auto_filename = False\n",
    "#Unused if auto_filename = True\n",
    "train_filename = 'compressed_all_jets_train.pkl'\n",
    "test_filename = 'compressed_all_jets_test.pkl'\n",
    "\n",
    "#Fraction of data to be saved\n",
    "data_frac = 1\n",
    "\n",
    "tree = uproot.open(ROOTFilePath)['CollectionTree']\n",
    "\n",
    "#n_jets = sum(tree.array('HLT_xAOD__JetContainer_TrigHLTJetDSSelectorCollectionAuxDyn.pt').counts)\n",
    "\n",
    "n_jets = sum(tree.array('AntiKt4EMTopoJetsAux.pt').counts)\n",
    "\n",
    "#Number of events to be processed\n",
    "maxEvents = int(n_jets*data_frac)\n",
    "\n",
    "#Specifies the dataset. The available 'columns' can be read with ttree.keys()\n",
    "#prefix = 'HLT_xAOD__JetContainer_TrigHLTJetDSSelectorCollectionAuxDyn'\n",
    "\n",
    "prefix1 = 'AntiKt4EMTopoJetsAux'\n",
    "prefix = 'AntiKt4EMTopoJetsAuxDyn'\n",
    "\n",
    "branchnames = [\n",
    "    # 4-momentum\n",
    "    prefix + '.pt',\n",
    "    prefix + '.eta',\n",
    "    prefix + '.phi',\n",
    "    prefix + '.m',\n",
    "    # Energy deposition in each calorimeter layer\n",
    "    # prefix + '.EnergyPerSampling',\n",
    "    # Area of jet,used for pile-up suppression (4-vector)\n",
    "    #prefix + '.ActiveArea',\n",
    "    prefix + '.ActiveArea4vec_eta',\n",
    "    prefix + '.ActiveArea4vec_m',\n",
    "    prefix + '.ActiveArea4vec_phi',\n",
    "    prefix + '.ActiveArea4vec_pt',\n",
    "    # prefix + '.JetGhostArea',\n",
    "    # Variables related to quality of jet\n",
    "    prefix + '.AverageLArQF',\n",
    "    # prefix + '.BchCorrCell',\n",
    "    prefix + '.NegativeE',\n",
    "    prefix + '.HECQuality',\n",
    "    prefix + '.LArQuality',\n",
    "    # Shape and position, most energetic cluster\n",
    "    prefix + '.Width',\n",
    "    prefix + '.WidthPhi',\n",
    "    prefix + '.CentroidR',\n",
    "    prefix + '.DetectorEta',\n",
    "    prefix + '.LeadingClusterCenterLambda',\n",
    "    prefix + '.LeadingClusterPt',\n",
    "    prefix + '.LeadingClusterSecondLambda',\n",
    "    prefix + '.LeadingClusterSecondR',\n",
    "    prefix + '.N90Constituents',\n",
    "    # Energy released in each calorimeter\n",
    "    prefix + '.EMFrac',\n",
    "    prefix + '.HECFrac',\n",
    "    # Variables related to the time of arrival of a jet\n",
    "    prefix + '.Timing',\n",
    "    prefix + '.OotFracClusters10',\n",
    "    prefix + '.OotFracClusters5',\n",
    "]\n",
    "\n",
    "#branchnames for the data in the float compression analysis\n",
    "compression_branchnames = [\n",
    "    # 4-momentum\n",
    "    prefix1 + '.pt',\n",
    "    prefix1 + '.eta',\n",
    "    prefix1 + '.phi',\n",
    "    prefix1 + '.m',\n",
    "    # Energy deposition in each calorimeter layer\n",
    "    # prefix + '.EnergyPerSampling',\n",
    "    # Area of jet,used for pile-up suppression (4-vector)\n",
    "    #prefix + '.ActiveArea',\n",
    "    prefix + '.ActiveArea4vec_eta',\n",
    "    prefix + '.ActiveArea4vec_m',\n",
    "    prefix + '.ActiveArea4vec_phi',\n",
    "    prefix + '.ActiveArea4vec_pt',\n",
    "    #prefix + '.NumTrkPt500',\n",
    "    #prefix + '.SumPtTrkPt500',\n",
    "    prefix + '.Jvt',\n",
    "    #prefix + '.GhostMuonSegmentCount',\n",
    "    #prefix + '.GhostTrack',\n",
    "    prefix + '.JVFCorr',\n",
    "    prefix + '.JvtRpt',\n",
    "    #prefix + '.NumTrkPt1000',\n",
    "    #prefix + '.TrackWidthPt1000',\n",
    "    prefix + '.FracSamplingMax',\n",
    "    prefix + '.FracSamplingMaxIndex',\n",
    "    # prefix + '.JetGhostArea',\n",
    "    # Variables related to quality of jet\n",
    "    #prefix + '.AverageLArQ',\n",
    "    # prefix + '.BchCorrCell',\n",
    "    #prefix + '.NegativeE',\n",
    "    #prefix1 + '.HECQuality',\n",
    "    #prefix + '.LArQuality',\n",
    "    # Shape and position, most energetic cluster\n",
    "    prefix + '.Width',\n",
    "    #prefix + '.WidthPhi',\n",
    "    #prefix + '.CentroidR',\n",
    "    #prefix + '.DetectorEta',\n",
    "    #prefix + '.LeadingClusterCenterLambda',\n",
    "    #prefix + '.LeadingClusterPt',\n",
    "    #prefix + '.LeadingClusterSecondLambda',\n",
    "    #prefix + '.LeadingClusterSecondR',\n",
    "    #prefix + '.N90Constituents',\n",
    "    # Energy released in each calorimeter\n",
    "    prefix + '.EMFrac',\n",
    "    #prefix + '.HECFrac',\n",
    "    # Variables related to the time of arrival of a jet\n",
    "    prefix + '.Timing',\n",
    "    #prefix + '.OotFracClusters10',\n",
    "    #prefix + '.OotFracClusters5',\n",
    "]\n",
    "\n",
    "df_dict = {}\n",
    "for pp, branchname in enumerate(compression_branchnames):\n",
    "    print(\"Reading: \" + branchname)\n",
    "    if 'EnergyPerSampling' in branchname:\n",
    "        pass\n",
    "    else:\n",
    "        variable = branchname.split('.')[1]\n",
    "        df_dict[variable] = []\n",
    "        jaggedX = tree.array(branchname)[:maxEvents]\n",
    "        for ii, arr in enumerate(jaggedX):\n",
    "            for kk, val in enumerate(arr):\n",
    "                df_dict[variable].append(val)\n",
    "\n",
    "print('Creating DataFrame...')\n",
    "df = pd.DataFrame(data=df_dict)\n",
    "print('Head of data:')\n",
    "print(df.head())\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=41)\n",
    "\n",
    "if auto_filename:\n",
    "    train_filename = \"all_jets_train_27D_\" + str(int(data_frac*100))+\"_percent.pkl\"\n",
    "    test_filename = \"all_jets_test_27D_\" + str(int(data_frac*100)) +\"_percent.pkl\"  \n",
    "    \n",
    "partial_train_percent = train.sample(frac=data_frac, random_state=42).reset_index(drop=True)  # Pick out a fraction of the data\n",
    "partial_test_percent = test.sample(frac=data_frac, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(\"Train data shape: \" + str(train.shape))\n",
    "print(\"Test data shape: \" + str(test.shape))\n",
    "      \n",
    "# Save train and test sets\n",
    "print('Saving ' + processed_folder + train_filename)\n",
    "train.to_pickle(processed_folder + train_filename)\n",
    "print(\"Saving \" + processed_folder + test_filename)\n",
    "test.to_pickle(processed_folder + test_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

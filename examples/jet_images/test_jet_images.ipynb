{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing a network for jet images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook will test a pre-trained network for jet images. The data used is created in examples/process_jet_images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: You have to change the path to the directory where your processed files are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Change this path to point to where you have stored the data: \n",
    "pkl_path = '/Users/nallenallis/Documents/LTH/Exjobb/data/jet images/images/jet_images_LAGAN_images_signal.pkl'\n",
    "\n",
    "# Read the .pkl-file with Pandas\n",
    "df = pd.read_pickle(pkl_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the DataFrame into two sets.\n",
    "split = round(0.8*len(df))\n",
    "train = df[:split] # indices 0 to split (80 %)\n",
    "test = df[split:] # indices split to end (20 %)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the two datasets as TensorDatasets to PyTorch (also loading all other classes we'll need later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from fastai import learner\n",
    "from fastai.data import core\n",
    "\n",
    "train_x = train\n",
    "test_x = test\n",
    "train_y = train_x  # y = x since we are building an autoencoder\n",
    "test_y = test_x\n",
    "\n",
    "# Constructs a tensor object of the data and wraps them in a TensorDataset object.\n",
    "train_ds = TensorDataset(torch.tensor(train_x.values, dtype=torch.float), torch.tensor(train_y.values, dtype=torch.float))\n",
    "valid_ds = TensorDataset(torch.tensor(test_x.values, dtype=torch.float), torch.tensor(test_y.values, dtype=torch.float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now set things up to load the data, and we use a batch size that was optimized by previous students...note also that this is fastai v2, migration thanks to Jessica Lastow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 256\n",
    "\n",
    "# Converts the TensorDataset into a DataLoader object and combines into one DataLoaders object (a basic wrapper\n",
    "# around several DataLoader objects). \n",
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=bs * 2)\n",
    "dls = core.DataLoaders(train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have an example network. Details aren't too important, as long as they match what was already trained for us...in this case we have a LeakyReLU, tanh activation function, and a number of layers that goes from 4 to 200 to 20 to 3 (number of features in the hidden layer that we pick for testing compression) and then back all the way to 4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AE_3D_200_LeakyReLU_test(\n",
       "  (en1): Linear(in_features=625, out_features=300, bias=True)\n",
       "  (en2): Linear(in_features=300, out_features=100, bias=True)\n",
       "  (de1): Linear(in_features=100, out_features=300, bias=True)\n",
       "  (de2): Linear(in_features=300, out_features=625, bias=True)\n",
       "  (tanh): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AE_3D_200_LeakyReLU_test(nn.Module):\n",
    "    def __init__(self, n_features=625):\n",
    "        super(AE_3D_200_LeakyReLU_test, self).__init__()\n",
    "        self.en1 = nn.Linear(n_features, 300)\n",
    "        self.en2 = nn.Linear(300, 100)\n",
    "        self.de1 = nn.Linear(100, 300)\n",
    "        self.de2 = nn.Linear(300, n_features)\n",
    "        #self.en1 = nn.Linear(n_features, 625)\n",
    "        #self.en2 = nn.Linear(625, 625)\n",
    "        #self.de1 = nn.Linear(625, 625)\n",
    "        #self.de2 = nn.Linear(625, n_features)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def encode(self, x):\n",
    "        return self.en2(self.tanh(self.en1(x)))\n",
    "\n",
    "    def decode(self, x):\n",
    "        return self.de2(self.tanh(self.de1(self.tanh(x))))\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encode(x)\n",
    "        return self.decode(z)\n",
    "\n",
    "    def describe(self):\n",
    "        return 'text'\n",
    "\n",
    "model = AE_3D_200_LeakyReLU_test()\n",
    "model.to('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have to pick a loss function - MSE loss is appropriate for a compression autoencoder since it reflects the [(input-output)/input] physical quantity that we want to minimize. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.metrics import mse\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "wd = 1e-6\n",
    "\n",
    "learn = learner.Learner(dls, model=model, wd=wd, loss_func=loss_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the pre-trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai.learner.Learner at 0x1213d0370>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#learn.load('bg_all_img_625-625-625-625')\n",
    "learn.load('bg_all_img_625-300-100-300-625')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#1) [0.08032570034265518]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "save_dir = \"plotOutput\"\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "model.to('cpu')\n",
    "\n",
    "data = torch.tensor(test.values, dtype=torch.float)\n",
    "pred = model(data)\n",
    "pred = pred.detach().numpy()\n",
    "data = data.detach().numpy()\n",
    "\n",
    "data_df = pd.DataFrame(data, columns=test.columns)\n",
    "pred_df = pd.DataFrame(pred, columns=test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_pickle(os.path.join(save_dir,'bg_all_img_625-300-100-300-625_output_signal.pkl'))\n",
    "#pred_df.to_pickle(os.path.join(save_dir,'bg_all_img_625-625-625-625-625_output_signal.pkl'))\n",
    "#pred_df.to_pickle(os.path.join(save_dir,'bg_all_img_625-300-100-300-625_output.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 526,
   "position": {
    "height": "463px",
    "left": "767px",
    "right": "20px",
    "top": "163px",
    "width": "526px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
